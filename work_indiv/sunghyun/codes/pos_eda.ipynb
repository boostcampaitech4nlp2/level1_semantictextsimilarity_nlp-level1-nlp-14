{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import transformers\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib 한글 패치\n",
    "from matplotlib import font_manager, rc\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    rc('font', family='Malgun Gothic')\n",
    "elif platform.system() == 'Darwin': # Mac\n",
    "    rc('font', family='AppleGothic')\n",
    "else: #linux\n",
    "    rc('font', family='NanumGothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>binary-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boostcamp-sts-v1-train-000</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~</td>\n",
       "      <td>반전도 있고,사랑도 있고재미도있네요.</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boostcamp-sts-v1-train-001</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>앗 제가 접근권한이 없다고 뜹니다;;</td>\n",
       "      <td>오, 액세스 권한이 없다고 합니다.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boostcamp-sts-v1-train-002</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>주택청약조건 변경해주세요.</td>\n",
       "      <td>주택청약 무주택기준 변경해주세요.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boostcamp-sts-v1-train-003</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>입사후 처음 대면으로 만나 반가웠습니다.</td>\n",
       "      <td>화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boostcamp-sts-v1-train-004</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>뿌듯뿌듯 하네요!!</td>\n",
       "      <td>꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>boostcamp-sts-v1-train-9319</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>교원능력개발평가에서 교원이 보호받을 수 있는 장치를 마련해야합니다</td>\n",
       "      <td>본인이 납부한 국민연금 금액을 기준으로 대출을 받을 수 있는 제도를 마련해 주세요</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>boostcamp-sts-v1-train-9320</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>여성가족부의 폐지를 원합니드</td>\n",
       "      <td>여성가족부 폐지를 청원 합니다.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>boostcamp-sts-v1-train-9321</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>국회의원들 월급좀 줄여주세요</td>\n",
       "      <td>공무원 봉급좀 줄이지좀 마세요</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>boostcamp-sts-v1-train-9322</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>오늘 못한 점심은 다음에 다시 츄라이 하기로 해요!!</td>\n",
       "      <td>오늘 못먹은 밥은 꼭 담에 먹기로 하고요!!</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>boostcamp-sts-v1-train-9323</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>법정공휴일 휴무관련 (근로자)</td>\n",
       "      <td>법정공휴일의 유급휴무화를 막아야 합니다.</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9324 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id            source  \\\n",
       "0      boostcamp-sts-v1-train-000      nsmc-sampled   \n",
       "1      boostcamp-sts-v1-train-001         slack-rtt   \n",
       "2      boostcamp-sts-v1-train-002  petition-sampled   \n",
       "3      boostcamp-sts-v1-train-003     slack-sampled   \n",
       "4      boostcamp-sts-v1-train-004     slack-sampled   \n",
       "...                           ...               ...   \n",
       "9319  boostcamp-sts-v1-train-9319  petition-sampled   \n",
       "9320  boostcamp-sts-v1-train-9320  petition-sampled   \n",
       "9321  boostcamp-sts-v1-train-9321  petition-sampled   \n",
       "9322  boostcamp-sts-v1-train-9322     slack-sampled   \n",
       "9323  boostcamp-sts-v1-train-9323  petition-sampled   \n",
       "\n",
       "                                  sentence_1  \\\n",
       "0     스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~   \n",
       "1                       앗 제가 접근권한이 없다고 뜹니다;;   \n",
       "2                             주택청약조건 변경해주세요.   \n",
       "3                     입사후 처음 대면으로 만나 반가웠습니다.   \n",
       "4                                 뿌듯뿌듯 하네요!!   \n",
       "...                                      ...   \n",
       "9319    교원능력개발평가에서 교원이 보호받을 수 있는 장치를 마련해야합니다   \n",
       "9320                         여성가족부의 폐지를 원합니드   \n",
       "9321                         국회의원들 월급좀 줄여주세요   \n",
       "9322           오늘 못한 점심은 다음에 다시 츄라이 하기로 해요!!   \n",
       "9323                        법정공휴일 휴무관련 (근로자)   \n",
       "\n",
       "                                         sentence_2  label  binary-label  \n",
       "0                              반전도 있고,사랑도 있고재미도있네요.    2.2           0.0  \n",
       "1                               오, 액세스 권한이 없다고 합니다.    4.2           1.0  \n",
       "2                                주택청약 무주택기준 변경해주세요.    2.4           0.0  \n",
       "3                      화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.    3.0           1.0  \n",
       "4                             꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!    0.0           0.0  \n",
       "...                                             ...    ...           ...  \n",
       "9319  본인이 납부한 국민연금 금액을 기준으로 대출을 받을 수 있는 제도를 마련해 주세요    0.2           0.0  \n",
       "9320                              여성가족부 폐지를 청원 합니다.    4.2           1.0  \n",
       "9321                               공무원 봉급좀 줄이지좀 마세요    0.6           0.0  \n",
       "9322                       오늘 못먹은 밥은 꼭 담에 먹기로 하고요!!    3.2           1.0  \n",
       "9323                         법정공휴일의 유급휴무화를 막아야 합니다.    1.4           0.0  \n",
       "\n",
       "[9324 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .. 상위 폴더\n",
    "train_pd = pd.read_csv('../../../../data/train.csv')\n",
    "train_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>binary-label</th>\n",
       "      <th>sentence_a</th>\n",
       "      <th>tokens_a</th>\n",
       "      <th>tokens_1</th>\n",
       "      <th>tokens_2</th>\n",
       "      <th>sen_len_a</th>\n",
       "      <th>sen_len_1</th>\n",
       "      <th>sen_len_2</th>\n",
       "      <th>tok_count_a</th>\n",
       "      <th>tok_count_1</th>\n",
       "      <th>tok_count_2</th>\n",
       "      <th>simple_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boostcamp-sts-v1-train-000</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~</td>\n",
       "      <td>반전도 있고,사랑도 있고재미도있네요.</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~ 반전도 있고,...</td>\n",
       "      <td>[스릴도있고, 반전도, 있고, 여느, 한국영화, 쓰레기들하고는, 차원이, 다르네요~...</td>\n",
       "      <td>[스릴도있고, 반전도, 있고, 여느, 한국영화, 쓰레기들하고는, 차원이, 다르네요~]</td>\n",
       "      <td>[반전도, 있고,사랑도, 있고재미도있네요.]</td>\n",
       "      <td>59</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boostcamp-sts-v1-train-001</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>앗 제가 접근권한이 없다고 뜹니다;;</td>\n",
       "      <td>오, 액세스 권한이 없다고 합니다.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>앗 제가 접근권한이 없다고 뜹니다;; 오, 액세스 권한이 없다고 합니다.</td>\n",
       "      <td>[앗, 제가, 접근권한이, 없다고, 뜹니다;;, 오,, 액세스, 권한이, 없다고, ...</td>\n",
       "      <td>[앗, 제가, 접근권한이, 없다고, 뜹니다;;]</td>\n",
       "      <td>[오,, 액세스, 권한이, 없다고, 합니다.]</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boostcamp-sts-v1-train-002</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>주택청약조건 변경해주세요.</td>\n",
       "      <td>주택청약 무주택기준 변경해주세요.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>주택청약조건 변경해주세요. 주택청약 무주택기준 변경해주세요.</td>\n",
       "      <td>[주택청약조건, 변경해주세요., 주택청약, 무주택기준, 변경해주세요.]</td>\n",
       "      <td>[주택청약조건, 변경해주세요.]</td>\n",
       "      <td>[주택청약, 무주택기준, 변경해주세요.]</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boostcamp-sts-v1-train-003</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>입사후 처음 대면으로 만나 반가웠습니다.</td>\n",
       "      <td>화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>입사후 처음 대면으로 만나 반가웠습니다. 화상으로만 보다가 리얼로 만나니 정말 반가...</td>\n",
       "      <td>[입사후, 처음, 대면으로, 만나, 반가웠습니다., 화상으로만, 보다가, 리얼로, ...</td>\n",
       "      <td>[입사후, 처음, 대면으로, 만나, 반가웠습니다.]</td>\n",
       "      <td>[화상으로만, 보다가, 리얼로, 만나니, 정말, 반가웠습니다.]</td>\n",
       "      <td>51</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boostcamp-sts-v1-train-004</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>뿌듯뿌듯 하네요!!</td>\n",
       "      <td>꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>뿌듯뿌듯 하네요!! 꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!</td>\n",
       "      <td>[뿌듯뿌듯, 하네요!!, 꼬옥, 실제로, 한번, 뵈어요, 뿌뿌뿌~!~!]</td>\n",
       "      <td>[뿌듯뿌듯, 하네요!!]</td>\n",
       "      <td>[꼬옥, 실제로, 한번, 뵈어요, 뿌뿌뿌~!~!]</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id            source  \\\n",
       "0  boostcamp-sts-v1-train-000      nsmc-sampled   \n",
       "1  boostcamp-sts-v1-train-001         slack-rtt   \n",
       "2  boostcamp-sts-v1-train-002  petition-sampled   \n",
       "3  boostcamp-sts-v1-train-003     slack-sampled   \n",
       "4  boostcamp-sts-v1-train-004     slack-sampled   \n",
       "\n",
       "                               sentence_1                    sentence_2  \\\n",
       "0  스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~          반전도 있고,사랑도 있고재미도있네요.   \n",
       "1                    앗 제가 접근권한이 없다고 뜹니다;;           오, 액세스 권한이 없다고 합니다.   \n",
       "2                          주택청약조건 변경해주세요.            주택청약 무주택기준 변경해주세요.   \n",
       "3                  입사후 처음 대면으로 만나 반가웠습니다.  화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.   \n",
       "4                              뿌듯뿌듯 하네요!!         꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!   \n",
       "\n",
       "   label  binary-label                                         sentence_a  \\\n",
       "0    2.2           0.0  스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~ 반전도 있고,...   \n",
       "1    4.2           1.0           앗 제가 접근권한이 없다고 뜹니다;; 오, 액세스 권한이 없다고 합니다.   \n",
       "2    2.4           0.0                  주택청약조건 변경해주세요. 주택청약 무주택기준 변경해주세요.   \n",
       "3    3.0           1.0  입사후 처음 대면으로 만나 반가웠습니다. 화상으로만 보다가 리얼로 만나니 정말 반가...   \n",
       "4    0.0           0.0                   뿌듯뿌듯 하네요!! 꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!   \n",
       "\n",
       "                                            tokens_a  \\\n",
       "0  [스릴도있고, 반전도, 있고, 여느, 한국영화, 쓰레기들하고는, 차원이, 다르네요~...   \n",
       "1  [앗, 제가, 접근권한이, 없다고, 뜹니다;;, 오,, 액세스, 권한이, 없다고, ...   \n",
       "2            [주택청약조건, 변경해주세요., 주택청약, 무주택기준, 변경해주세요.]   \n",
       "3  [입사후, 처음, 대면으로, 만나, 반가웠습니다., 화상으로만, 보다가, 리얼로, ...   \n",
       "4           [뿌듯뿌듯, 하네요!!, 꼬옥, 실제로, 한번, 뵈어요, 뿌뿌뿌~!~!]   \n",
       "\n",
       "                                          tokens_1  \\\n",
       "0  [스릴도있고, 반전도, 있고, 여느, 한국영화, 쓰레기들하고는, 차원이, 다르네요~]   \n",
       "1                       [앗, 제가, 접근권한이, 없다고, 뜹니다;;]   \n",
       "2                                [주택청약조건, 변경해주세요.]   \n",
       "3                     [입사후, 처음, 대면으로, 만나, 반가웠습니다.]   \n",
       "4                                    [뿌듯뿌듯, 하네요!!]   \n",
       "\n",
       "                              tokens_2  sen_len_a  sen_len_1  sen_len_2  \\\n",
       "0             [반전도, 있고,사랑도, 있고재미도있네요.]         59         38         20   \n",
       "1            [오,, 액세스, 권한이, 없다고, 합니다.]         40         20         19   \n",
       "2               [주택청약, 무주택기준, 변경해주세요.]         33         14         18   \n",
       "3  [화상으로만, 보다가, 리얼로, 만나니, 정말, 반가웠습니다.]         51         22         28   \n",
       "4          [꼬옥, 실제로, 한번, 뵈어요, 뿌뿌뿌~!~!]         32         10         21   \n",
       "\n",
       "   tok_count_a  tok_count_1  tok_count_2  simple_label  \n",
       "0           11            8            3             2  \n",
       "1           10            5            5             4  \n",
       "2            5            2            3             2  \n",
       "3           11            5            6             3  \n",
       "4            7            2            5             0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply 함수로 일괄 적용\n",
    "\n",
    "# sentence 합치기\n",
    "train_pd['sentence_a'] = train_pd['sentence_1'] + ' ' + train_pd['sentence_2']\n",
    "\n",
    "# 공백 기준으로 토큰 나누기\n",
    "train_pd['tokens_a']=train_pd['sentence_a'].apply(lambda x: x.split())\n",
    "train_pd['tokens_1']=train_pd['sentence_1'].apply(lambda x: x.split())\n",
    "train_pd['tokens_2']=train_pd['sentence_2'].apply(lambda x: x.split())\n",
    "\n",
    "# 문장 길이, 토큰 개수 칼럼 만들기\n",
    "train_pd['sen_len_a']=train_pd['sentence_a'].apply(lambda x: len(x))\n",
    "train_pd['sen_len_1']=train_pd['sentence_1'].apply(lambda x: len(x))\n",
    "train_pd['sen_len_2']=train_pd['sentence_2'].apply(lambda x: len(x))\n",
    "\n",
    "train_pd['tok_count_a']=train_pd['tokens_a'].apply(lambda x: len(x))\n",
    "train_pd['tok_count_1']=train_pd['tokens_1'].apply(lambda x: len(x))\n",
    "train_pd['tok_count_2']=train_pd['tokens_2'].apply(lambda x: len(x))\n",
    "\n",
    "# label 단순화, 소숫점 버림\n",
    "train_pd['simple_label'] = train_pd['label'].apply(lambda x: int(x))\n",
    "\n",
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer160 = transformers.AutoTokenizer.from_pretrained('klue/roberta-small')\n",
    "tokenizer512 = transformers.AutoTokenizer.from_pretrained('klue/roberta-small', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c52a71ddbf44add99573fd3e1f6a8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/9324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = train_pd.drop(columns=['id'])\n",
    "data160 = []\n",
    "for idx, item in tqdm(df.iterrows(), desc='tokenizing', total=len(df)):\n",
    "# 두 입력 문장을 [SEP] 토큰으로 이어붙여서 전처리합니다.\n",
    "    text = '[SEP]'.join([item[text_column] for text_column in ['sentence_1', 'sentence_2']])\n",
    "    outputs = tokenizer160(text, add_special_tokens=True, padding='max_length', max_length=160, truncation=True)\n",
    "    data160.append(outputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5c7c1e77ca477e9b8fc5b5036f1778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/9324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = train_pd.drop(columns=['id'])\n",
    "data512 = []\n",
    "for idx, item in tqdm(df.iterrows(), desc='tokenizing', total=len(df)):\n",
    "# 두 입력 문장을 [SEP] 토큰으로 이어붙여서 전처리합니다.\n",
    "    text = '[SEP]'.join([item[text_column] for text_column in ['sentence_1', 'sentence_2']])\n",
    "    outputs = tokenizer160(text, add_special_tokens=True, padding='max_length', truncation=True)\n",
    "    data512.append(outputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "[0, 15314, 2119, 2689, 2088, 8984, 2119, 1513, 2088, 11934, 3629, 16516, 6614, 2031, 19521, 2259, 4540, 2052, 4405, 2203, 2182, 97, 2, 8984, 2119, 1513, 2088, 16, 3784, 2119, 1513, 2088, 2070, 2044, 2119, 2689, 2203, 2182, 18, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(data160[0]))\n",
    "print(data160[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[0, 15314, 2119, 2689, 2088, 8984, 2119, 1513, 2088, 11934, 3629, 16516, 6614, 2031, 19521, 2259, 4540, 2052, 4405, 2203, 2182, 97, 2, 8984, 2119, 1513, 2088, 16, 3784, 2119, 1513, 2088, 2070, 2044, 2119, 2689, 2203, 2182, 18, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(data512[0]))\n",
    "print(data512[0][:160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>binary-label</th>\n",
       "      <th>sentence_a</th>\n",
       "      <th>tokens_a</th>\n",
       "      <th>tokens_1</th>\n",
       "      <th>tokens_2</th>\n",
       "      <th>sen_len_a</th>\n",
       "      <th>sen_len_1</th>\n",
       "      <th>sen_len_2</th>\n",
       "      <th>tok_count_a</th>\n",
       "      <th>tok_count_1</th>\n",
       "      <th>tok_count_2</th>\n",
       "      <th>simple_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>boostcamp-sts-v1-train-2412</td>\n",
       "      <td>nsmc-rtt</td>\n",
       "      <td>‥ 김민희를알수록 의심되는 정체. 완벽한연기. 완벽한몰입과스릴. 작은반전. 무엇보다...</td>\n",
       "      <td>‥ 김민희를 알면 알수록 의심스러워진다. 완벽한 연기. 완벽한 몰입과 스릴. 작은 ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>‥ 김민희를알수록 의심되는 정체. 완벽한연기. 완벽한몰입과스릴. 작은반전. 무엇보다...</td>\n",
       "      <td>[‥, 김민희를알수록, 의심되는, 정체., 완벽한연기., 완벽한몰입과스릴., 작은반...</td>\n",
       "      <td>[‥, 김민희를알수록, 의심되는, 정체., 완벽한연기., 완벽한몰입과스릴., 작은반...</td>\n",
       "      <td>[‥, 김민희를, 알면, 알수록, 의심스러워진다., 완벽한, 연기., 완벽한, 몰입...</td>\n",
       "      <td>209</td>\n",
       "      <td>94</td>\n",
       "      <td>114</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id    source  \\\n",
       "2412  boostcamp-sts-v1-train-2412  nsmc-rtt   \n",
       "\n",
       "                                             sentence_1  \\\n",
       "2412  ‥ 김민희를알수록 의심되는 정체. 완벽한연기. 완벽한몰입과스릴. 작은반전. 무엇보다...   \n",
       "\n",
       "                                             sentence_2  label  binary-label  \\\n",
       "2412  ‥ 김민희를 알면 알수록 의심스러워진다. 완벽한 연기. 완벽한 몰입과 스릴. 작은 ...    4.0           1.0   \n",
       "\n",
       "                                             sentence_a  \\\n",
       "2412  ‥ 김민희를알수록 의심되는 정체. 완벽한연기. 완벽한몰입과스릴. 작은반전. 무엇보다...   \n",
       "\n",
       "                                               tokens_a  \\\n",
       "2412  [‥, 김민희를알수록, 의심되는, 정체., 완벽한연기., 완벽한몰입과스릴., 작은반...   \n",
       "\n",
       "                                               tokens_1  \\\n",
       "2412  [‥, 김민희를알수록, 의심되는, 정체., 완벽한연기., 완벽한몰입과스릴., 작은반...   \n",
       "\n",
       "                                               tokens_2  sen_len_a  sen_len_1  \\\n",
       "2412  [‥, 김민희를, 알면, 알수록, 의심스러워진다., 완벽한, 연기., 완벽한, 몰입...        209         94   \n",
       "\n",
       "      sen_len_2  tok_count_a  tok_count_1  tok_count_2  simple_label  \n",
       "2412        114           43           17           26             4  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd[train_pd['sen_len_a']==max(train_pd['sen_len_a'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "[0, 15314, 2119, 2689, 2088, 8984, 2119, 1513, 2088, 11934, 3629, 16516, 6614, 2031, 19521, 2259, 4540, 2052, 4405, 2203, 2182, 97, 2, 8984, 2119, 1513, 2088, 16, 3784, 2119, 1513, 2088, 2070, 2044, 2119, 2689, 2203, 2182, 18, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(data160[2412]))\n",
    "print(data160[0][:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[0, 15314, 2119, 2689, 2088, 8984, 2119, 1513, 2088, 11934, 3629, 16516, 6614, 2031, 19521, 2259, 4540, 2052, 4405, 2203, 2182, 97, 2, 8984, 2119, 1513, 2088, 16, 3784, 2119, 1513, 2088, 2070, 2044, 2119, 2689, 2203, 2182, 18, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(data512[2412]))\n",
    "print(data512[0][:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer max_length 자료 조사\n",
    "\n",
    "- 우선, 실험적으로 max_length 변화에 차이가 존재하지 않았음\n",
    "- Tokenzier 호출 시 max_length는 truncation/padding 의 maximum length를 control\n",
    "- Padding에 들어간 'max_length'는 model의 최대 수용 가능 입력 길이를 의미하며 이것을 사용하면 해당 길이까지 padding 처리해줌\n",
    "    - ![Tokenizer max_length Description](../../../src/max_length_d.png) \n",
    "    - ![Padding max_length Description](../../../src/padding_d.png)  \n",
    "    - [Hugging Face tokenzier doc](https://huggingface.co/docs/transformers/main_classes/tokenizer)\n",
    "    - [Hugging Face pad_trunc doc](https://huggingface.co/docs/transformers/pad_truncation)\n",
    "    #\n",
    "- 사용한 Tokenizer는 [BertTokenizer](https://huggingface.co/klue/roberta-small/blob/main/tokenizer_config.json)\n",
    "- 아래는 관련 문서\n",
    "    - [AutoTokenzier Source Code](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#autotokenizer)\n",
    "    - [AutoConfig Source Code](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#autoconfig)\n",
    "    - [BertConfig 문서](https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#transformers.BertConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3a4da20e6844be8f1baf0167dcb24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/9324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('klue/roberta-small')\n",
    "df = train_pd.drop(columns=['id'])\n",
    "data = []\n",
    "for idx, item in tqdm(df.iterrows(), desc='tokenizing', total=len(df)):\n",
    "# 두 입력 문장을 [SEP] 토큰으로 이어붙여서 전처리합니다.\n",
    "    text = '[SEP]'.join([item[text_column] for text_column in ['sentence_1', 'sentence_2']])\n",
    "    outputs = tokenizer(text, add_special_tokens=True, padding='do_not_pad', truncation=True)\n",
    "    data.append(outputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(map(lambda x : len(x), data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]스릴##도##있##고반전##도있##고여느한국##영화쓰레기##들##하고##는차원##이다르##네##요~[SEP]반전##도있##고,사랑##도있##고##재##미##도##있##네##요.[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(tokenizer.batch_decode(data[0][:160]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]‥김민##희##를##알##수록의심##되##는정체.완벽##한##연##기.완벽##한##몰##입##과##스##릴.작##은##반##전.무엇##보##다현실##성이##있##는‥인간##의한계##와그걸벗어나##려##는욕심##을##보##여##준‥내보##기##엔완벽##한시나리오.[SEP]‥김민##희##를알##면알##수록의심##스##러워##진다.완벽##한연기.완벽##한몰입##과스릴.작##은회전.무엇##보##다현실##적인시나리오##다.인간##의한계##와그것##을벗어나##고##자하##는욕망##을보여준다.시나리오##가완벽##했##던것같##다.[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(tokenizer.batch_decode(data[2412][:160]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd['bert_tokenized']=pd.Series(map(lambda x : ''.join(tokenizer.batch_decode(x)),data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>bert_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~</td>\n",
       "      <td>반전도 있고,사랑도 있고재미도있네요.</td>\n",
       "      <td>[CLS]스릴##도##있##고반전##도있##고여느한국##영화쓰레기##들##하고##는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>앗 제가 접근권한이 없다고 뜹니다;;</td>\n",
       "      <td>오, 액세스 권한이 없다고 합니다.</td>\n",
       "      <td>[CLS]앗제##가접근##권##한##이없##다고[UNK];;[SEP]오,액세##스권...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>주택청약조건 변경해주세요.</td>\n",
       "      <td>주택청약 무주택기준 변경해주세요.</td>\n",
       "      <td>[CLS]주택##청##약##조건변경##해##주##세요.[SEP]주택##청##약무주택...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>입사후 처음 대면으로 만나 반가웠습니다.</td>\n",
       "      <td>화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.</td>\n",
       "      <td>[CLS]입사##후처음대면##으로만나반가웠##습##니다.[SEP]화상##으로##만보...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>뿌듯뿌듯 하네요!!</td>\n",
       "      <td>꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!</td>\n",
       "      <td>[CLS]뿌듯##뿌##듯하##네##요!![SEP]꼬##옥실제로한번뵈##어요뿌##뿌#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>교원능력개발평가에서 교원이 보호받을 수 있는 장치를 마련해야합니다</td>\n",
       "      <td>본인이 납부한 국민연금 금액을 기준으로 대출을 받을 수 있는 제도를 마련해 주세요</td>\n",
       "      <td>[CLS]교원##능력##개발##평가##에서교원##이보호##받##을수있##는장치##를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>여성가족부의 폐지를 원합니드</td>\n",
       "      <td>여성가족부 폐지를 청원 합니다.</td>\n",
       "      <td>[CLS]여성##가족##부##의폐지##를원##합##니##드[SEP]여성##가족##부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>국회의원들 월급좀 줄여주세요</td>\n",
       "      <td>공무원 봉급좀 줄이지좀 마세요</td>\n",
       "      <td>[CLS]국회의원##들월급##좀줄여##주##세요[SEP]공무원봉급##좀줄이##지##...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>오늘 못한 점심은 다음에 다시 츄라이 하기로 해요!!</td>\n",
       "      <td>오늘 못먹은 밥은 꼭 담에 먹기로 하고요!!</td>\n",
       "      <td>[CLS]오늘못한점심##은다음##에다시츄##라이하##기##로해요!![SEP]오늘못#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>법정공휴일 휴무관련 (근로자)</td>\n",
       "      <td>법정공휴일의 유급휴무화를 막아야 합니다.</td>\n",
       "      <td>[CLS]법정##공##휴일휴무##관##련(근로자)[SEP]법정##공##휴일##의유급...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9324 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sentence_1  \\\n",
       "0     스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~   \n",
       "1                       앗 제가 접근권한이 없다고 뜹니다;;   \n",
       "2                             주택청약조건 변경해주세요.   \n",
       "3                     입사후 처음 대면으로 만나 반가웠습니다.   \n",
       "4                                 뿌듯뿌듯 하네요!!   \n",
       "...                                      ...   \n",
       "9319    교원능력개발평가에서 교원이 보호받을 수 있는 장치를 마련해야합니다   \n",
       "9320                         여성가족부의 폐지를 원합니드   \n",
       "9321                         국회의원들 월급좀 줄여주세요   \n",
       "9322           오늘 못한 점심은 다음에 다시 츄라이 하기로 해요!!   \n",
       "9323                        법정공휴일 휴무관련 (근로자)   \n",
       "\n",
       "                                         sentence_2  \\\n",
       "0                              반전도 있고,사랑도 있고재미도있네요.   \n",
       "1                               오, 액세스 권한이 없다고 합니다.   \n",
       "2                                주택청약 무주택기준 변경해주세요.   \n",
       "3                      화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.   \n",
       "4                             꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!   \n",
       "...                                             ...   \n",
       "9319  본인이 납부한 국민연금 금액을 기준으로 대출을 받을 수 있는 제도를 마련해 주세요   \n",
       "9320                              여성가족부 폐지를 청원 합니다.   \n",
       "9321                               공무원 봉급좀 줄이지좀 마세요   \n",
       "9322                       오늘 못먹은 밥은 꼭 담에 먹기로 하고요!!   \n",
       "9323                         법정공휴일의 유급휴무화를 막아야 합니다.   \n",
       "\n",
       "                                         bert_tokenized  \n",
       "0     [CLS]스릴##도##있##고반전##도있##고여느한국##영화쓰레기##들##하고##는...  \n",
       "1     [CLS]앗제##가접근##권##한##이없##다고[UNK];;[SEP]오,액세##스권...  \n",
       "2     [CLS]주택##청##약##조건변경##해##주##세요.[SEP]주택##청##약무주택...  \n",
       "3     [CLS]입사##후처음대면##으로만나반가웠##습##니다.[SEP]화상##으로##만보...  \n",
       "4     [CLS]뿌듯##뿌##듯하##네##요!![SEP]꼬##옥실제로한번뵈##어요뿌##뿌#...  \n",
       "...                                                 ...  \n",
       "9319  [CLS]교원##능력##개발##평가##에서교원##이보호##받##을수있##는장치##를...  \n",
       "9320  [CLS]여성##가족##부##의폐지##를원##합##니##드[SEP]여성##가족##부...  \n",
       "9321  [CLS]국회의원##들월급##좀줄여##주##세요[SEP]공무원봉급##좀줄이##지##...  \n",
       "9322  [CLS]오늘못한점심##은다음##에다시츄##라이하##기##로해요!![SEP]오늘못#...  \n",
       "9323  [CLS]법정##공##휴일휴무##관##련(근로자)[SEP]법정##공##휴일##의유급...  \n",
       "\n",
       "[9324 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd[['sentence_1','sentence_2','bert_tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('proyum')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a2c19c83d7f3b65ee17ae108a20f4e4922ba888bfb431bd5469b97b46eabc80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
